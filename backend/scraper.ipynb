{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f841d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing\n",
    "from bs4 import BeautifulSoup, SoupStrainer, NavigableString\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de69a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating scrapable objects from 2 landing pages (acts and regulations)\n",
    "\n",
    "landing_pages = [\"https://laws-lois.justice.gc.ca/eng/acts/\", \"https://laws-lois.justice.gc.ca/eng/regulations/\"]\n",
    "# alpha_links = []  # holding links of all alphabetical act/regulation pages\n",
    "\n",
    "# creating a list of doc titles\n",
    "doc_titles = []\n",
    "doc_links = []\n",
    "\n",
    "for landing_page in landing_pages:\n",
    "  # creating a soup for each page\n",
    "  page = requests.get(landing_page)\n",
    "  soup = BeautifulSoup(page.text, features=\"html.parser\")\n",
    "\n",
    "\n",
    "  alpha_link = \"\"\n",
    "\n",
    "  # entering all alphabetical act/regulation pages into\n",
    "  for item in soup.find_all(\"a\"):\n",
    "    try:\n",
    "      if item[\"class\"] == [\"btn\", \"btn-default\"]:\n",
    "        alpha_page = item[\"href\"]\n",
    "        alpha_link = f\"{landing_page}{alpha_page}\"\n",
    "\n",
    "        alpha_page = requests.get(alpha_link)\n",
    "        alpha_soup = BeautifulSoup(alpha_page.text, features=\"html.parser\")\n",
    "\n",
    "        for item in alpha_soup.find_all(\"a\"):\n",
    "          if \"class\" in item.attrs.keys():\n",
    "            if item.attrs[\"class\"] == [\"TocTitle\"]:\n",
    "              if item.string != None:\n",
    "                doc_titles.append(str(item.string[2:-2]))\n",
    "                doc_links.append(f\"{landing_page}{item.get('href')}\")\n",
    "    except: \n",
    "      continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4771\n",
      "4771\n"
     ]
    }
   ],
   "source": [
    "doc_titles.append(\"The Constitution Acts 1867 to 1982\")\n",
    "doc_links.append(\"https://laws-lois.justice.gc.ca/eng/Const/index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd783303",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/names.txt\", \"a\") as file, open(\"data/links.txt\", \"a\") as file1:\n",
    "  for i in range(3):\n",
    "    name = doc_titles[i]\n",
    "    link = doc_links[i]\n",
    "\n",
    "    scrapable_link = \"\"\n",
    "    try:\n",
    "      scrapable_link = requests.get(f\"{link[:-11]}/FullText.html\")\n",
    "      scrapable_link.encoding = scrapable_link.apparent_encoding\n",
    "      scrapable_soup = BeautifulSoup(scrapable_link.text, \"html.parser\")\n",
    "      # if the page can be found, append title to names.txt\n",
    "\n",
    "      file.write(f\"{doc_titles[i]}\\n\")\n",
    "      file1.write(f\"{doc_links[i]}\\n\")\n",
    "    \n",
    "      # write scraped data into associated file\n",
    "      with open(f\"data/scraped_content/{doc_titles[i].replace(' ', '_')}.txt\", \"a\", encoding=\"utf-8\") as file2:\n",
    "        for item in scrapable_soup.find_all([\"p\", \"h2\", \"h3\", \"h4\"]):\n",
    "          if (item.name == \"p\"):\n",
    "            for descendant in item.descendants:\n",
    "              if isinstance(descendant, NavigableString):\n",
    "                if str(descendant) != \"Marginal note:\":\n",
    "                  file2.write(descendant)\n",
    "            file2.write(\"\\n\")\n",
    "          \n",
    "          elif (item.name == \"h2\"):\n",
    "            try:\n",
    "              if \"Part\" in item[\"class\"]:\n",
    "                for descendant in item.descendants:\n",
    "                  if isinstance(descendant, NavigableString):\n",
    "                    if str(descendant) != \"Marginal note:\":\n",
    "                      file2.write(descendant)\n",
    "                file2.write(\"\\n\")\n",
    "            except:\n",
    "              continue\n",
    "          \n",
    "          elif (item.name ==  \"h3\" or item.name == \"h4\"):\n",
    "            try:\n",
    "              if \"Subheading\" in item[\"class\"]:\n",
    "                for descendant in item.descendants:\n",
    "                  if isinstance(descendant, NavigableString):\n",
    "                    if str(descendant) != \"Marginal note:\":\n",
    "                      file2.write(descendant)\n",
    "                file2.write(\"\\n\")\n",
    "            except:\n",
    "              continue\n",
    "\n",
    "    except:\n",
    "      continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
